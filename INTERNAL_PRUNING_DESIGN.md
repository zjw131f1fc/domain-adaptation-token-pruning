# LLM å†…éƒ¨å‰ªæè®¾è®¡æ–¹æ¡ˆ

## ğŸ“Œ æ ¸å¿ƒå†³ç­–
- **å‰ªææ—¶æœº**: åªåœ¨ Prefill é˜¶æ®µå‰ªæ
- **å®ç°æ–¹å¼**: ä½¿ç”¨ PyTorch Hooks
- **ç›®æ ‡**: åœ¨ LLM æŸäº›å±‚ä¹‹åæ’å…¥å‰ªæå™¨ï¼Œå‡å°‘åç»­å±‚çš„è®¡ç®—é‡

---

## ğŸ” å…³é”®çŸ¥è¯†ç‚¹ï¼ˆä»æºç åˆ†æå¾—å‡ºï¼‰

### 1. Generate æµç¨‹
**ä½ç½®**: `transformers/generation/utils.py:2219`

```python
# generate() æ–¹æ³•çš„æ ¸å¿ƒå¾ªç¯
while not_finished:
    # å‡†å¤‡è¾“å…¥
    model_inputs = prepare_inputs_for_generation(input_ids, **model_kwargs)

    # ç¬¬ä¸€æ¬¡è¿­ä»£ï¼ˆPrefillï¼‰
    if is_prefill:
        outputs = self(**model_inputs, return_dict=True)
        is_prefill = False  # æ ‡è®°å®Œæˆ
    # åç»­è¿­ä»£ï¼ˆDecodeï¼‰
    else:
        outputs = model_forward(**model_inputs, return_dict=True)

    # æ›´æ–° KV cache
    model_kwargs = self._update_model_kwargs_for_generation(outputs, model_kwargs, ...)

    # æå– logits å¹¶é€‰æ‹©ä¸‹ä¸€ä¸ª token
    next_token_logits = outputs.logits[:, -1, :]
    next_tokens = argmax(next_token_logits, dim=-1)

    # æ‹¼æ¥åˆ°åºåˆ—
    input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
```

**å…³é”®ç‚¹**:
- âœ… Prefill å’Œ Decode éƒ½è°ƒç”¨ `forward()`
- âœ… Prefill: `past_key_values=None`, `input_ids=[B, L]`
- âœ… Decode: `past_key_values=cache`, `input_ids=[B, 1]`
- âœ… `is_prefill` æ ‡å¿—åœ¨ç¬¬ä¸€æ¬¡ forward åè‡ªåŠ¨è®¾ä¸º `False`

---

### 2. LLaVA Forward æµç¨‹
**ä½ç½®**: `transformers/models/llava/modeling_llava.py:367`

```python
# LlavaForConditionalGeneration.forward()
def forward(self, input_ids, pixel_values, past_key_values=None, ...):
    # 1. è°ƒç”¨ LlavaModel
    outputs = self.model(
        input_ids=input_ids,
        pixel_values=pixel_values,
        past_key_values=past_key_values,
        ...
    )

    # 2. è®¡ç®— logits
    hidden_states = outputs[0]
    logits = self.lm_head(hidden_states[:, slice_indices, :])

    return LlavaCausalLMOutputWithPast(
        logits=logits,
        past_key_values=outputs.past_key_values,  # è¿”å› KV cache
        ...
    )
```

**LlavaModel.forward() å†…éƒ¨**:
```python
# modeling_llava.py:243
def forward(self, input_ids, pixel_values, ...):
    # 1. è·å–æ–‡æœ¬ embeddings
    inputs_embeds = self.get_input_embeddings()(input_ids)

    # 2. å¦‚æœæœ‰å›¾åƒï¼Œå¤„ç†å¹¶æ›¿æ¢ <image> token
    if pixel_values is not None:
        # é€šè¿‡ vision_tower ç¼–ç 
        image_features = self.get_image_features(pixel_values, ...)

        # æ‰¾åˆ° <image> token ä½ç½®å¹¶æ›¿æ¢
        special_image_mask = self.get_placeholder_mask(input_ids, inputs_embeds, image_features)
        inputs_embeds = inputs_embeds.masked_scatter(special_image_mask, image_features)

    # 3. è°ƒç”¨ language_modelï¼ˆæ ¸å¿ƒ Transformer å±‚ï¼‰
    outputs = self.language_model(
        inputs_embeds=inputs_embeds,
        attention_mask=attention_mask,
        past_key_values=past_key_values,  # KV cache
        ...
    )

    return outputs
```

**å…³é”®ç‚¹**:
- âœ… `pixel_values` åªåœ¨ Prefill æ—¶ä¼ å…¥ï¼ˆç”± `prepare_inputs_for_generation` æ§åˆ¶ï¼‰
- âœ… `language_model` æ˜¯çœŸæ­£çš„ Transformer å±‚å †æ ˆ
- âœ… Hook åº”è¯¥æ³¨å†Œåœ¨ `language_model.layers[i]` ä¸Š

---

### 3. Prepare Inputs for Generation
**ä½ç½®**: `transformers/models/llava/modeling_llava.py:453`

```python
def prepare_inputs_for_generation(
    self,
    input_ids,
    past_key_values=None,
    pixel_values=None,
    cache_position=None,
    ...
):
    # è°ƒç”¨çˆ¶ç±»å‡†å¤‡åŸºç¡€è¾“å…¥
    model_inputs = super().prepare_inputs_for_generation(...)

    # å…³é”®åˆ¤æ–­ï¼šåªåœ¨ Prefill æ—¶ä¼ é€’ pixel_values
    if cache_position[0] == 0:
        model_inputs["pixel_values"] = pixel_values

    return model_inputs
```

**å…³é”®ç‚¹**:
- âœ… `cache_position[0] == 0` åˆ¤æ–­æ˜¯å¦ä¸º Prefill
- âœ… Decode æ—¶ `pixel_values` ä¸º `None`ï¼Œè·³è¿‡å›¾åƒå¤„ç†

---

### 4. KV Cache ç»“æ„
**ä½ç½®**: `transformers/cache_utils.py`

```python
class DynamicCache:
    """
    å­˜å‚¨ç»“æ„:
    - key_cache: List[Tensor]  # æ¯å±‚ä¸€ä¸ª: [batch, num_heads, seq_len, head_dim]
    - value_cache: List[Tensor]  # æ¯å±‚ä¸€ä¸ª: [batch, num_heads, seq_len, head_dim]
    """

    def update(self, key_states, value_states, layer_idx):
        """æ›´æ–°æŸä¸€å±‚çš„ cache"""
        if layer_idx == 0 or len(self.key_cache) <= layer_idx:
            # ç¬¬ä¸€æ¬¡ï¼šç›´æ¥ä¿å­˜
            self.key_cache.append(key_states)
            self.value_cache.append(value_states)
        else:
            # åç»­ï¼šæ‹¼æ¥æ–° token
            self.key_cache[layer_idx] = torch.cat([self.key_cache[layer_idx], key_states], dim=2)
            self.value_cache[layer_idx] = torch.cat([self.value_cache[layer_idx], value_states], dim=2)
```

**å…³é”®ç‚¹**:
- âœ… Cache æŒ‰å±‚å­˜å‚¨ï¼Œæ¯å±‚ç‹¬ç«‹
- âœ… Prefill: ä¿å­˜å®Œæ•´åºåˆ—çš„ KV
- âœ… Decode: æ¯æ¬¡æ‹¼æ¥æ–° token çš„ KV
- âœ… **å¦‚æœ Prefill æ—¶å‰ªæäº†ï¼Œcache å­˜å‚¨çš„æ˜¯å‰ªæåçš„é•¿åº¦** âœ…

---

## ğŸ¯ å†…éƒ¨å‰ªææ–¹æ¡ˆï¼ˆHook-Basedï¼‰

### æ ¸å¿ƒæ€è·¯
1. **æ³¨å†Œ Hooks**: åœ¨ `language_model.layers[i]` çš„æŸäº›å±‚æ³¨å†Œ `forward_hook`
2. **Prefill æ—¶å‰ªæ**: Hook æ£€æµ‹åˆ° `past_key_values=None` æ—¶åº”ç”¨å‰ªæ
3. **Decode æ—¶è·³è¿‡**: Hook æ£€æµ‹åˆ° `past_key_values` å­˜åœ¨æ—¶è·³è¿‡å‰ªæ
4. **ä¿®æ”¹ hidden_states**: åœ¨ hook ä¸­ç›´æ¥ç§»é™¤è¢«å‰ªæçš„ token
5. **æ›´æ–°ä½ç½®ä¿¡æ¯**: è®°å½•æ–°çš„ `vision_positions`ï¼Œä¾›åç»­å±‚ä½¿ç”¨

### Hook å‡½æ•°ä¼ªä»£ç 
```python
def pruning_hook(module, input, output):
    # 1. æ£€æŸ¥æ˜¯å¦æ˜¯ Prefillï¼ˆé€šè¿‡æ£€æŸ¥è¾“å…¥é•¿åº¦æˆ– past_key_valuesï¼‰
    is_prefill = (input[1] is None)  # past_key_values ä¸º None

    if not is_prefill:
        return output  # Decode é˜¶æ®µï¼Œè·³è¿‡å‰ªæ

    # 2. æå– hidden_states
    hidden_states = output[0]  # [batch, seq_len, hidden_dim]

    # 3. è¯†åˆ« vision token ä½ç½®
    vision_start, vision_end = get_vision_positions()
    vision_hidden = hidden_states[:, vision_start:vision_end+1, :]

    # 4. åº”ç”¨å‰ªæå™¨
    soft_mask, hard_mask = generator(vision_hidden, question_embedding)

    # 5. ç§»é™¤è¢«å‰ªæçš„ tokenï¼ˆæ ¹æ® hard_maskï¼‰
    kept_indices = torch.nonzero(hard_mask[:, :, 0]).squeeze()
    pruned_vision = vision_hidden[:, kept_indices, :]

    # 6. é‡æ–°æ‹¼æ¥åºåˆ—
    new_hidden = torch.cat([
        hidden_states[:, :vision_start, :],
        pruned_vision,
        hidden_states[:, vision_end+1:, :]
    ], dim=1)

    # 7. æ›´æ–°è¾“å‡º
    output[0] = new_hidden
    return output
```

---

## âš ï¸ å…³é”®æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ

### æŒ‘æˆ˜ 1: Batch å†…ä¸åŒæ ·æœ¬å‰ªææ•°é‡ä¸åŒ
**é—®é¢˜**: ä¸åŒæ ·æœ¬å¯èƒ½ä¿ç•™ä¸åŒæ•°é‡çš„ tokenï¼Œå¯¼è‡´åºåˆ—é•¿åº¦ä¸ä¸€è‡´

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ A: Paddingï¼ˆæ¨èï¼Œç®€å•ï¼‰
max_kept = max(num_kept_per_sample)
for each sample:
    if num_kept < max_kept:
        pad with zeros
        update attention_mask to mask out padding

# æ–¹æ¡ˆ B: åˆ†åˆ«å¤„ç†ï¼ˆå¤æ‚ï¼Œä½†æ›´é«˜æ•ˆï¼‰
# å°† batch æ‹†åˆ†ï¼Œé€ä¸ªæ ·æœ¬å¤„ç†
```

### æŒ‘æˆ˜ 2: Attention Mask æ›´æ–°
**é—®é¢˜**: å‰ªæååºåˆ—é•¿åº¦å˜åŒ–ï¼Œéœ€è¦æ›´æ–° `attention_mask`

**è§£å†³æ–¹æ¡ˆ**:
```python
# Hook éœ€è¦åŒæ—¶ä¿®æ”¹ attention_mask
# æ–¹æ³• 1: é€šè¿‡å…¨å±€çŠ¶æ€ä¼ é€’
self.pruner_manager.updated_attention_mask = new_mask

# æ–¹æ³• 2: å­˜å‚¨åœ¨ model_kwargs ä¸­ï¼ˆéœ€è¦åœ¨å¤–éƒ¨å¤„ç†ï¼‰
```

### æŒ‘æˆ˜ 3: Position IDs
**é—®é¢˜**: å‰ªæåä½ç½®ç¼–ç éœ€è¦è°ƒæ•´

**è§£å†³æ–¹æ¡ˆ**:
```python
# ä¿æŒåŸå§‹ä½ç½®ç¼–ç ï¼Œåªç§»é™¤ token
# æˆ–è€…ï¼šé‡æ–°ç”Ÿæˆè¿ç»­çš„ä½ç½®ç¼–ç 
new_position_ids = torch.arange(0, new_seq_len, device=device)
```

---

## ğŸ“Š FLOPs è®¡ç®—

### ç†è®ºè®¡ç®—
```python
def calculate_flops_reduction(
    num_layers=32,
    hidden_dim=4096,
    num_heads=32,
    original_seq_len=676,  # 100 text + 576 vision
    pruned_seq_len=376,     # 100 text + 276 vision (å‰ªæ 300 ä¸ª)
    pruning_layer=10        # åœ¨ç¬¬ 10 å±‚å‰ªæ
):
    # æ¯å±‚ Attention çš„ FLOPs ä¸»è¦å–å†³äº seq_len^2
    # FLOPs_attention â‰ˆ 4 * seq_len^2 * hidden_dim

    # å‰ 10 å±‚ï¼ˆå‰ªæå‰ï¼‰
    flops_before = pruning_layer * 4 * (original_seq_len ** 2) * hidden_dim

    # å 22 å±‚ï¼ˆå‰ªæåï¼‰
    flops_after = (num_layers - pruning_layer) * 4 * (pruned_seq_len ** 2) * hidden_dim

    # Baselineï¼ˆä¸å‰ªæï¼‰
    flops_baseline = num_layers * 4 * (original_seq_len ** 2) * hidden_dim

    reduction = (flops_baseline - (flops_before + flops_after)) / flops_baseline

    return {
        "baseline": flops_baseline,
        "with_pruning": flops_before + flops_after,
        "reduction": f"{reduction * 100:.2f}%"
    }
```

**é¢„æœŸç»“æœ**ï¼ˆå‰ªæ 300/576 ä¸ª tokenï¼Œåœ¨ç¬¬ 10 å±‚ï¼‰:
- å‰ 10 å±‚: 100% FLOPsï¼ˆæœªå‰ªæï¼‰
- å 22 å±‚: ~44% FLOPsï¼ˆåºåˆ—é•¿åº¦ä» 676 é™åˆ° 376ï¼‰
- **æ€»ä½“å‡å°‘**: ~38% FLOPs

---

## ğŸš€ å®ç°æ­¥éª¤

### Step 1: åˆ›å»º InternalPrunerManager
- [ ] å®ç° Hook æ³¨å†Œé€»è¾‘
- [ ] å®ç°å‰ªæ Hook å‡½æ•°
- [ ] å¤„ç† Batch padding
- [ ] è®°å½•å‰ªæç»Ÿè®¡

### Step 2: é›†æˆåˆ° Backbone
- [ ] åœ¨ `__init__` ä¸­åˆå§‹åŒ– pruner manager
- [ ] ä¿®æ”¹ `forward_from_embeddings` ä¼ é€’ vision_positions
- [ ] æ·»åŠ  enable/disable æ¥å£

### Step 3: ä¿®æ”¹è®­ç»ƒæµç¨‹
- [ ] åœ¨ `train_step` ä¸­ä¼ é€’å¿…è¦ä¿¡æ¯
- [ ] æ”¶é›†å‰ªæç»Ÿè®¡
- [ ] è®¡ç®—å‰ªæç›¸å…³ loss

### Step 4: è¯„ä¼°ä¸ FLOPs è®¡ç®—
- [ ] å®ç° FLOPs è®¡ç®—å·¥å…·
- [ ] å¯¹æ¯”å‰ªæå‰åå·®å¼‚
- [ ] è¯„ä¼°ç”Ÿæˆè´¨é‡

---

## ğŸ”§ é…ç½®ç¤ºä¾‹

```yaml
method_settings:
  use_internal_pruning: true
  internal_pruner_layers: [10]  # åœ¨ç¬¬ 10 å±‚åå‰ªæ
  target_token_num: 276          # ç›®æ ‡ä¿ç•™ 276 ä¸ª vision token

  # åŸæœ‰å‚æ•°ä¿æŒä¸å˜
  gen_num_layers: 2
  gen_num_heads: 2
  ...
```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

### Transformers æºç ä½ç½®
1. **Generate ä¸»æµç¨‹**: `transformers/generation/utils.py:2219-2566`
2. **LLaVA Forward**: `transformers/models/llava/modeling_llava.py:367-451`
3. **Prepare Inputs**: `transformers/models/llava/modeling_llava.py:453-481`
4. **KV Cache**: `transformers/cache_utils.py`

### å…³é”®ä»£ç è¡Œ
- Prefill åˆ¤æ–­: `modeling_llava.py:476` (`cache_position[0] == 0`)
- Generate å¾ªç¯: `generation/utils.py:2764-2834`
- Image å¤„ç†: `modeling_llava.py:272-283`
- Language Model è°ƒç”¨: `modeling_llava.py:285-292`

---

## ğŸ’¡ æ³¨æ„äº‹é¡¹

1. **åªåœ¨ Prefill å‰ªæ**: Decode é˜¶æ®µä¸å‰ªæï¼Œä½¿ç”¨ Prefill ç”Ÿæˆçš„å‹ç¼© cache
2. **ä¿æŒæ¢¯åº¦æµ**: Hook ä¸­çš„æ‰€æœ‰æ“ä½œå¿…é¡»å¯å¾®
3. **Attention Mask ä¸€è‡´æ€§**: å‰ªæåéœ€è¦åŒæ­¥æ›´æ–° mask
4. **Batch å¤„ç†**: ä½¿ç”¨ padding å¤„ç†ä¸åŒé•¿åº¦
5. **æ€§èƒ½å¼€é”€**: Hook æœ‰ä¸€å®šå¼€é”€ï¼Œä½†ç›¸æ¯”å‰ªææ”¶ç›Šå¯å¿½ç•¥

---

## ğŸ¯ é¢„æœŸæ•ˆæœ

- **è®¡ç®—é‡å‡å°‘**: 30-40% FLOPsï¼ˆå–å†³äºå‰ªææ¯”ä¾‹å’Œå±‚ä½ç½®ï¼‰
- **ç”Ÿæˆé€Ÿåº¦**: Prefill é˜¶æ®µå¯èƒ½ç•¥æ…¢ï¼ˆå‰ªæå¼€é”€ï¼‰ï¼ŒDecode é˜¶æ®µæ›´å¿«ï¼ˆåºåˆ—çŸ­ï¼‰
- **å†…å­˜å ç”¨**: KV cache å‡å°‘ï¼ˆå­˜å‚¨å‰ªæåçš„åºåˆ—ï¼‰
- **ç”Ÿæˆè´¨é‡**: å–å†³äºå‰ªæå™¨çš„è®­ç»ƒæ•ˆæœ

---

*æœ€åæ›´æ–°: 2025-12-14*
*ä½œè€…: Claude Code*
