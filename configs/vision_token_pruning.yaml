# Vision Token Pruning with GAN 配置文件

global_settings:
  seed: 42
  device: "cuda"
  dtype: "half"  # 训练数据类型: "half" (float16) 或 "float" (float32)
  pytorch_cuda_alloc_conf: "expandable_segments:True"
  dataset_cache_dir: "/data/users/zjw/dataset_cache"
  hf_cache_dir: "/data/users/zjw/huggingface_cache"
  save_dir: "./outputs/checkpoints"
  log_dir: "./outputs/logs"
  study_name: "gan_vtp"  # Vision Token Pruning研究名称

trainer_settings:  # 训练框架设置
  type: "deep-learning"
  name: "basic-pytorch"
  dl_settings:
    epochs: 2  # 2个epochs
    batch_size: 8  # batch_size=8
    optimizers:
      generator:  # Generator优化器（Token Merger + Layer Pruners）
        type: "adam"
        lr: "1e-04"  # 默认值，会被Optuna覆盖
      discriminator:  # Discriminator优化器
        type: "adam"
        lr: "1e-04"  # 默认值，会被Optuna覆盖
    print_loss_every_batches: 5  # 减少日志打印
    eval_every_batches: 10  # 每25个batch评估一次
    eval_max_samples: 15  # 每次评估50个样本
    save_every_batches: 0  # Optuna搜索时禁用保存（加速）
    save_every_epochs: 0  # Optuna搜索时禁用保存
    optuna_eval_interval_batches: 25  # Optuna评估间隔：每25个batch报告一次
    grad_clip_max_norm: 1.0  # 梯度裁剪：1.0更保守，防止GAN训练不稳定

manager_settings:
  name: "basic"
  mode: "direct"  # null=单任务模式, "optuna"=超参数搜索, "batch_configs"=批量配置, "direct"=直接运行
  num_subtasks: 1  # 单任务：每个trial需要3个GPU，5张卡只够开1个
  available_gpus: [1,3,5,7]  # 更新可用GPU列表
  gpus_per_subtask: 4  # 每个trial使用3个GPU
  poll_interval: 5.0  # 轮询间隔，减少CPU占用

search_settings:
  enable: false
  type: "optuna"
  n_trials: 200  # 减少trial数量（单worker串行执行）
  study_name: "gan_vtp_hp_search"
  pruner:
    type: "successive_halving"
    min_resource: 2  # 最少跑2个评估点才能被剪枝
    reduction_factor: 3
    min_early_stopping_rate: 0
  sampler:
    type: "tpe"
    n_startup_trials: 10  # TPE warmup：前10个trial随机采样
    multivariate: true  # 考虑参数间相关性
  params:
    # 学习率（对数搜索，跨数量级）
    trainer_settings.dl_settings.optimizers.generator.lr:
      type: "float"
      low: 1.0e-6
      high: 1.0e-3
      log: true
    trainer_settings.dl_settings.optimizers.discriminator.lr:
      type: "float"
      low: 1.0e-6
      high: 1.0e-3
      log: true

    # Loss权重（对数搜索，跨3-4个数量级）
    # 让Optuna自动探索最优尺度，不做过多假设
    method_settings.adv_loss_weight:
      type: "float"
      low: 0.01
      high: 100.0
      log: true
    method_settings.task_loss_weight:
      type: "float"
      low: 0.1
      high: 100.0
      log: true
    method_settings.sparsity_weight:
      type: "float"
      low: 1.0e-4
      high: 10.0
      log: true
    method_settings.token_count_loss_weight:
      type: "float"
      low: 1.0e-4
      high: 10.0
      log: true

    # Token Merge配置
    method_settings.merge_ratio:
      type: "float"
      low: 0.3
      high: 0.9
      log: false

    # Discriminator配置
    method_settings.disc_reinit_prob:
      type: "float"
      low: 0.0
      high: 0.3
      log: false
    method_settings.disc_dropout:
      type: "float"
      low: 0.05
      high: 0.4
      log: false

dataset_settings:  # 数据集配置
  name: "vqa-vqav2"  # 数据集名称
  split:
    train: 800  # 训练集：800样本（充分训练）
    test: 200  # 测试集：200样本（准确评估）
  category_priority:
    enable: false  # 禁用类别均衡，加快数据加载
    values:
      - train: "mean"
      - test: "mean"
  fast_load_no_random: true  # 快速加载模式（Optuna搜索时加速）

config_settings:
  enable_dict_overrides: true
  enable_yaml_overrides: true
  log_config_on_load: true

backbone_settings:  # 多模态大模型骨架配置
  type: "mllm"  # 骨架类型
  name: "llava-1.5-7b"  # 模型名称
# name: "llava-1.5-7b" "qwen-2.5-3b"
  mllm_settings:
    device_map: "balanced"  # 显存分配策略（balanced/auto）
    max_text_tokens: 128  # 最大文本token数
    max_vision_tokens: 1600  # 最大视觉token数（减少降低显存占用）
    image_max_size: 800  # 图像最大尺寸（减少降低vision token数）
    vision_dim: 1024  # CLIP Vision Encoder输出维度（ViT-L/14）
    hidden_dim: 4096  # LLaMA Hidden State维度（7B模型）

method_settings:
  # ==================== Token Merger配置（新增） ====================
  merger_type: "question_aware"  # "simple" 或 "question_aware"（使用V2版本）
  merge_ratio: 1.0  # 保留比例

  # ==================== Layer-wise Pruner配置（新增） ====================
  pruning_layers: [5, 10, 15]  # 要剪枝的LLM层索引
  pruner_d_internal: 512  # Pruner内部维度
  pruner_num_heads: 4  # Cross-attention头数
  pruner_type: "cross_attention"  # "cross_attention" 或 "simple"

  # ==================== 剪枝目标配置 ====================
  use_token_num_target: true  # true=使用绝对token数目标, false=使用稀疏度比例
  target_token_num: 200  # 目标保留的绝对token数（use_token_num_target=true时生效）
  target_sparsity: 0.3  # 目标稀疏度（use_token_num_target=false时生效，0.3表示剪掉30%）

  # ==================== Sparsity Loss配置 ====================
  sparsity_loss_only_on_excess: true  # true=只在超出目标时惩罚（强约束）, false=双向惩罚
  sparsity_weight: 0 # 1 # 10 # 1e-4  # Sparsity约束loss权重（强惩罚）
  token_count_loss_weight: 0 # 1 # 10.0 # 1e-3  # Token总数loss权重（弱惩罚，鼓励减少token）

  # ==================== Temperature Annealing（新增） ====================
  temperature: 1.0  # 初始temperature
  temperature_min: 0.1  # 最小temperature
  temperature_anneal_rate: 0.5  # Anneal比例（前50%步数进行annealing）

  # ==================== Hard Pruning配置（评估时使用） ====================
  hard_pruning_threshold: 0.5  # Hard剪枝阈值（soft_mask > threshold则保留）

  # Discriminator配置
  disc_num_layers: 3  # 使用的LLM隐层数量
  disc_d_d: 512  # 隐层维度
  disc_dropout: 0.2  # Dropout比率
  disc_target_layers: [-1, -3, -5]  # 目标LLM层索引
  disc_reinit_prob: 0.2  # 每个batch重初始化Discriminator的概率
  disc_use_spectral_norm: false  # 谱归一化（GAN稳定性）

  # 损失权重
  adv_loss_weight: 0 # 1 # 1.0  # 对抗损失权重
  task_loss_weight: 1 # 100.0 # 25.0  # 任务损失权重

evaluation_settings:  # 评估配置
  eval_mode: ["origin", "soft", "hard"]
